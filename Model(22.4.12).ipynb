{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81823f71",
   "metadata": {},
   "source": [
    "## 4. 데이터 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965df7f2",
   "metadata": {},
   "source": [
    "## 4.1 단순 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8571330",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 종속 변수와 독립변수가 분리되어 있는 경우\n",
    "X_train, X_테스트(검증), y_train, y_테스트(검증) = train_test_split(독립변수, 종속변수, test_size=, random_state=, shuffle=, stratify=종속변수)\n",
    "\n",
    "# 종속 변수가 한 데이터프레임에 있는 경우\n",
    "df_train, df_테스트(혹은 검증) = train_test_split(데이터, test_size= , random_state=, shuffle=, stratify=)\n",
    "\n",
    "X_train = df_train[Y제외]\n",
    "Y_train = df_train[Y선택]\n",
    "X_valid = df_valid[Y제외]\n",
    "Y_valid = df_valid[Y선택]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27166aa",
   "metadata": {},
   "source": [
    "- stratify를 적용하면 종속변수의 원래 비율대로 split, train_test_split에서는 기본값이 False\n",
    "- cross_validation을 하려면 \n",
    "    - 원래 데이터를 train, test로 나누고 다시 train을 가지고 cross validation\n",
    "    - 원본 -> train, test\n",
    "    - train -> cross_validation(train, valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c492596c",
   "metadata": {},
   "source": [
    "# 5. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1e25f1",
   "metadata": {},
   "source": [
    "- 데이터가 매우 크고 고차원이면 Tree 기반 모델 대신 선형 모형을 사용해야 하는가?\n",
    "    - RandomForest는 sparse matrix 데이터에서 잘 작동하지 않음\n",
    "    - 속도와 메모리 사용에 제약이 있는 경우\n",
    "        - 선형모델이 더 적합(파이썬 라이브러리를 활용한 머신러닝 p.121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6d2935d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import GridSearchCV, learning_curve\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bc4fa5",
   "metadata": {},
   "source": [
    "## 5.1 Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b7a5c8",
   "metadata": {},
   "source": [
    "## 5.1.1 Support Vector Machine(linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c51668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(kernel='linear', C=1e10, gamma=0.1, probability=True)\n",
    "model.fit(훈련_X, 훈련_Y)\n",
    "\n",
    "# C : 슬랙 변수 크게하면 넘어가는 데이터를 없게 하고 작게 하면 마진을 최대화\n",
    "# probability : predict_proba를 반환하느냐 안하느냐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dbe8ef",
   "metadata": {},
   "source": [
    "- 속성값\n",
    "- n_support_ : 각 클래스의 서포트 개수\n",
    "- support_vectors_ : 각 클래스의 서포트의 x값. x+ 와 x-\n",
    "- coef_ : w벡터\n",
    "- intercept_ : -w0\n",
    "- dual_coef_ : 각 원소가 a_i * y_i 로 이루어진 벡터(-a와 +a를 의미)\n",
    "               더하면 0됨 ∑ai*yi = 0 (w0으로 미분값)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e33ac0f",
   "metadata": {},
   "source": [
    "## 5.1.2 Radial Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860f3116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(kernel='rbf', C=, gamma=, probability=True)\n",
    "model.fit(훈련_X, 훈련_Y)\n",
    "\n",
    "# kernel : poly, rbf, sigmoid ... \n",
    "# gamma : 크면 과적합"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8613b6fa",
   "metadata": {},
   "source": [
    "## 5.1.3 KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ae3ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors= )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a3e6b4",
   "metadata": {},
   "source": [
    "## 5.1.4 DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45481f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "트리 = DecisionTreeClassifier(criterion='entropy or gini', max_depth=, random_state=)\n",
    "트리.fit(훈련_X, 훈련_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9476792f",
   "metadata": {},
   "source": [
    "- random_state: feature를 고른 후 각 threshold 별로 정보획득량을 계산하는데 모든 구간을 다 잘라보는게 아니고 랜덤으로 골라서 나눠본다\n",
    "\n",
    "\n",
    "- **사전 가지치기(보통 1개만 지정해도 충분)**\n",
    "    - max_depth: 최대 몇번 나눌 것인가\n",
    "    - max_leaf_nodes: 리프 노드의 최대 개수\n",
    "    - min_sample_split: 노드를 분할하기 위한 최소한의 샘플 데이터 수\n",
    "    - min_samples_leaf: 리프 노드가 되기 위한 최소한의 샘플 데이터 개수\n",
    "        - 비대칭적 데이터의 경우 특정 클래스의 데이터가 매우 작을 수 있으므로 이런 경우 작게 설정\n",
    "    - min_impurity_decrease: 분할로 얻어질 불순도 감소 최솟값\n",
    "\n",
    "\n",
    "- **사후 가지치기**\n",
    "    - ccp_alpha: 비용 복잡도 기반(파이썬 라이브러리를 활용한 머신러닝 p.106)\n",
    "\n",
    "\n",
    "- DecisionTree기반 모델은 데이터 스케일의 영향을 받지 않으므로 특성의 정규화나 표준화같은 전처리 과정이 필요없음\n",
    "- 이진 특성과 연속적인 특성이 혼합되어 있을때도 잘 작동\n",
    "- Greedy 문제가 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb8e6ff",
   "metadata": {},
   "source": [
    "#### 개별 모델 하이퍼 파라미터에 따른 성능 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fafd698",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "parameter_index = list(range(최소, 최대))\n",
    "scores = pd.Series()\n",
    "\n",
    "for i in parameter_index:\n",
    "    model = KNeighborsClassifier(n_neighbors=i)\n",
    "    model.fit(훈련_X, 훈련_Y)\n",
    "    prediction = model.predict(검증_X)\n",
    "    scores = scores.append(pd.Series(metrics.accuracy_score(prediction, 검증_Y)))  # 여기서는 score로 accuracy 사용\n",
    "\n",
    "plt.subplots(figsize=(12, 6))\n",
    "plt.plot(parameter_index, scores)\n",
    "plt.xticks(parameter_index)\n",
    "plt.show()\n",
    "print('The max value is', scores.max())\n",
    "print('The best parameter is', parameter_index[np.argmax(a)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac3f323",
   "metadata": {},
   "source": [
    "- accuracy : metrics.accuracy_score\n",
    "- precision : metrics.precision_score\n",
    "- recall : metrics.recall_score\n",
    "- roc_auc : metrics.roc_auc_score\n",
    "- f1 : metrics.f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563a8985",
   "metadata": {},
   "source": [
    "#### predict_proba에서 임계점 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56745398",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_array = []\n",
    "for temp_thres in np.arange(0, 1, 0.01):\n",
    "    threshold = temp_thres\n",
    "    prediction1 = (model.predict_proba(검증_X)[:, 1] > temp_thres).astype(int)\n",
    "    temp_score = 100 * metrics.accuracy_score(prediction1, 검증_Y)\n",
    "    print('Accuracy for rbf SVM is {:.2f}%', 100 * metrics.accuracy_score(prediction1, 검증_Y))\n",
    "    score_array.append(temp_score)\n",
    "    \n",
    "# 시각화\n",
    "plt.plot(np.arange(0, 1, 0.01), score_array)\n",
    "plt.xlabel('threshold')\n",
    "plt.ylabel('accuracy score')\n",
    "\n",
    "# 가장 높은 accuracy_score에서의 threshold\n",
    "print(argmax(score_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b6583d",
   "metadata": {},
   "source": [
    "## 5.2 Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985089aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d207168e",
   "metadata": {},
   "source": [
    "# 6. Ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4b0d89",
   "metadata": {},
   "source": [
    "## 6.1 Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1522c0a",
   "metadata": {},
   "source": [
    "## 6.1.1 Voting Classifier\n",
    "- 분류 문제에서만 가능하다\n",
    "- 회귀문제는 여러 모델을 동시에 쓰기 힘듦\n",
    "- 성능이 0.5 이하의 모델을 사용하면 더욱 성능이 나빠진다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95b939f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "model1 = 분류기1(파라미터)\n",
    "model2 = 분류기2(파라미터)\n",
    "model3 = 분류기3(파라미터)\n",
    "\n",
    "voting_model = VotingClassifier(estimators=[('이름1', model1),\n",
    "                                            ('이름2', model2),\n",
    "                                            ('이름3', model3)],\n",
    "                               voting='소프트 or 하드', weights=[비율1, 비율2, 비율3], n_jobs=-1)\n",
    "voting_model.fit(훈련_X, 훈련_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3b3b50",
   "metadata": {},
   "source": [
    "## 6.1.2 Bagging\n",
    "- 분산이 높은 모델에서 효과가 좋음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6147eebb",
   "metadata": {},
   "source": [
    "### 6.1.2.1 일반적인 Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ca0b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "model = BaggingClassifier(base모델, n_estimators=, bootstrap=, max_samples=, max_features=, random_state=, n_jobs=-1)\n",
    "model.fit(훈련_X, 훈련_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7b75c0",
   "metadata": {},
   "source": [
    "- n_estimators: 모형 갯수\n",
    "- bootstrap: 데이터의 중복 사용 여부. 디폴트 True\n",
    "- max_samples: 선택할 샘플의 수 혹은 비율 디폴트 1.0\n",
    "- bootstrap_features: 특징 차원 중복 디폴트 False\n",
    "- max_features: 독립 변수중  선택할 차원의 수 혹은 비율 디폴트 1.0\n",
    "\n",
    "- 분류기가 predict_proba()를 지원하는 경우 확률값을 평균하여 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201063c7",
   "metadata": {},
   "source": [
    "### 6.1.2.2 RandomForest\n",
    "- DecisionTree에 기반한 Bagging, 부트스트랩 샘플링도 이루어진다\n",
    "- 각 노드마다 일부의 feature를 주고 그 안에서 가장 정보획득이 높은 Feature 선택\n",
    "- 분기 후에 데이터를 더 주지 않는다(지도학습-47. 25분)\n",
    "- 결과는 출력 레이블의 확률로 soft voting방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce8d234",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "모델 = RandomForestClassifier(n_estimators=, max_features=, max_depth=, random_state=, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efd004f",
   "metadata": {},
   "source": [
    "- max_features: 기본값 'auto', 분류에서는 sqrt(n_features), 회귀에서는 n_features\n",
    "- 다른 매개변수 DecisionTree와 같음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808d05c0",
   "metadata": {},
   "source": [
    "### 6.1.2.3 Extremely Randomized Trees\n",
    "- 각 노드에서 분기할 때 무조건 랜덤 Feature\n",
    "- threshold는 가장 좋은 임계값 사용\n",
    "- 부트스트랩 샘플은 적용되지 않음\n",
    "- 무작위성을 증가시키면 편향은 늘어나지만 분산은 감소\n",
    "- 계산비용은 적지만 무작위성때문에 많은 Tree가 필요, RandomForest가 더 선호된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848ab707",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63322a76",
   "metadata": {},
   "source": [
    "## 6.1.3 Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484e9fc4",
   "metadata": {},
   "source": [
    "## 6.1.3.1 Adaboost\n",
    "\n",
    "- 손실함수가 적은 분류기를 새 멤버로 영입\n",
    "- 각 멤버가 서로 다른 투표권이 있음, 투표권은 손실함수로 정함\n",
    "- 데이터마다 가중치가 다름. 기존 위원회가 틀린 데이터의 가중치가 올라감\n",
    "- 즉 새 멤버가 되려면 기존 위원회가 틀린 문제를 맞히는 모델이 새 멤버가 될 가능성이 높음\n",
    "- 각 데이터에 대한 가중치를 저장하는 방법은 데사스쿨 참고\n",
    "- 이진 분류만 가능\n",
    "- 강한 아웃라이어가 있는 경우 오버피팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18eeb845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "모델 = AdaBoostClassifier(기반모델, n_estimators=, learning_rate=)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e2ba45",
   "metadata": {},
   "source": [
    "- learning_rate: 1 이하로 주면 새로운 멤버의 가중치를 강제로 낮춤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772de5fb",
   "metadata": {},
   "source": [
    "## 6.1.3.2 XgBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11bfd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "\n",
    "model_xgb = xgboost.XGBClassifier(n_estimators=1, \n",
    "                                  max_depth=, \n",
    "                                  objective='binary:logistic', \n",
    "                                  learning_rate=, \n",
    "                                  subsample=, \n",
    "                                  min_child_weight=, \n",
    "                                  colsample_bytree=, \n",
    "                                  scale_pos_weight=, \n",
    "                                  gamma=, \n",
    "                                  reg_alpha=, \n",
    "                                  reg_lambda=,\n",
    "                                  random_state=, n_jobs=-1)  # 사이킷런 래퍼 클래스\n",
    "\n",
    "model_xgb.fit(X데이터, y데이터,\n",
    "              eval_set=[(검증X, 검증y)],\n",
    "              eval_metric=평가함수,\n",
    "              early_stopping_rounds=,\n",
    "              verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859a2bef",
   "metadata": {},
   "source": [
    "- learning_rate: 디폴트 0.1\n",
    "    - 그레디언트에 곱하는 스텝 사이즈, 보통 0.01 ~ 0.2\n",
    "- min_child_weight: 디폴트 1\n",
    "    - 트리에서 추가적으로 가지를 나눌지를 결정하기 위해 필요한 데이터들의 weight 총합\n",
    "    - 여기서 말하는 weight는 loss값의 2차 미분값을 의미. \n",
    "    - 회귀:MSE에서 (y-h_hat)^2의 2차 미분 값은 1, 즉 데이터 개수만큼 합한 것이므로 가지를 나누는데 필요한 총 데이터 개수란 의미\n",
    "    - binary:logistic(시그모이드)에서는 σ(y_hat)을 2번 미분한 값의 데이터 개수만큼 합\n",
    "- gamma: 디폴트 0\n",
    "    - 트리의 리프 노드를 추가적으로 나눌지를 결정할 최소 손실 감소 값\n",
    "- max_depth: 디폴트 6\n",
    "    - 보통 3~10\n",
    "- subsample : 디폴트 1\n",
    "    - weak learner가 학습에 사용하는 데이터의 샘플링 비율, 보통 0.5 ~ 1\n",
    "- colsample_bytree: 디폴트 1\n",
    "    - max_feature와 유사. 트리 생성에 사용하는 feature 샘플링\n",
    "- reg_lambda: 디폴트 1\n",
    "    - L2 Regularization\n",
    "- reg_alpha: 디폴트 0\n",
    "    - L1 Regularization\n",
    "- scale_pos_weight: 디폴트 1\n",
    "    - 비대칭 클래스 데이터 세트의 균형을 유지하기 위한 파라미터\n",
    "    \n",
    "**학습 태스크 파라미터**\n",
    "- objective : 손실 함수 정의\n",
    "    - binary:logistic, multi:softmax\n",
    "- eval_metric : 검증에 사용되는 함수, 디폴트 회귀:rmse, 분류:error\n",
    "    - rmse\n",
    "    - mae\n",
    "    - logloss\n",
    "    - error: Binary classification error rate(0.5 threshold)\n",
    "    - merror: Multiclass classification error rate\n",
    "    - mlogloss: Multiclass logloss\n",
    "    - auc\n",
    "    \n",
    "**속성**\n",
    "- best_ntree_limit\n",
    "- best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd772efb",
   "metadata": {},
   "source": [
    "## 6.1.3.3 LightGBM\n",
    "- 데이터가 작을 때 과적합이 발생할 수 있음(약 1만건 이하)\n",
    "- 균형 트리분할 대신 최대 손실 값을 갖는 리프 노드를 지속적으로 분할하면서 비대칭적\n",
    "- 카테고리 피처의 자동 변환과 최적 분할\n",
    "    - 원핫 인코딩을 사용하지 않고도 카테고리형 피처를 최적으로 변환\n",
    "- GPU 사용 가능\n",
    "- 연속값 데이터를 이산화해서 메모리 사용 감소\n",
    "- 분포가 밀집되어 있는 데이터에서 좋음, 고차원 희소 데이터에서는 서포트 벡터 머신이나 신경망보다 저조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c07beb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "모델 = LGBClassifier(n_estimators=100, num_leaves=31, min_child_samples=20, max_depth=-1, \n",
    "                            learning_rate=0.1, random_state=, n_jobs=-1, early_stopping_rounds=)\n",
    "모델.fit(categorical_feature=, feature_name=, eval_set=, eval_metric=)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9916f7",
   "metadata": {},
   "source": [
    "- min_child_samples(min_data_in_leaf): 디폴트 20\n",
    "    - 리프 노드가 되기 위한 최소한의 데이터 수\n",
    "- num_leaves: 31\n",
    "    - 하나의 트리가 가질 수 있는 최대 리프 개수\n",
    "    - 2의 max_depth 제곱보다 작아야 한다?\n",
    "- boosting_type : 트리를 생성하는 알고리즘 (디폴트 gbdt)\n",
    "    - gbdt: 일반적인 그래디언트 부스팅 결정 트리\n",
    "    - rf: 랜덤 포레스트\n",
    "    - goss: gradient one side sampling\n",
    "        - 내부적으로 LightGBM은 첫 번째 1/learning_rate 반복 동안 gbdt 모드를 사용합니다.\n",
    "- min_split_gain: 디폴트 0.0\n",
    "    - 추가 리프노드를 만들기 위한 최소 손실 감소량\n",
    "- max_cat_group: 디폴트 64\n",
    "    - 카테고리 변수의 범주가 너무 많은 경우 과적합 방지를 위해 그룹으로 묶음\n",
    "- subsample(bagging_fraction): 디폴트 1.0\n",
    "    - 데이터 샘플링 비율\n",
    "- subsample_freq(bagging_freq): 디폴트 0\n",
    "    - k 번째 이터레이션 마다 배깅\n",
    "- colsample_bytree(feature_fraction): 디폴트 1.0\n",
    "    - feature 샘플링 비율\n",
    "- reg_lambda: 디폴트 0.0\n",
    "    - 피처 개수가 많을 경우 적용 검토\n",
    "- reg_alpha: 디폴트 0.0\n",
    "- max_bin: 디폴트 255\n",
    "    - 히스토그램 빈 갯수\n",
    "- device_type: gpu or gpu\n",
    "- drop_rate: 디폴트 0.1\n",
    "    - dropout동안 drop되는 이전 트리의 비율\n",
    "    - boosting_type이 'gbdt'일 경우에는 적용안됨(확인 필요)\n",
    "- max_drop: 디폴트 50\n",
    "    - 한 번의 부스팅 반복 동안 드롭된 트리의 최대 수\n",
    "- is_unbalance: 공식문서 참고\n",
    "- seed: \n",
    "    - porto competition 2등 솔루션에서 사용\n",
    "- class_weight: 디폴트 None\n",
    "    - 'balanced'로 하면 손실함수를 계산할 때 unbalanced 클래스에 대해 가중치를 다르게 매김\n",
    "- subsample for bin\n",
    "    - number of data that sampled to construct feature discrete bins\n",
    "    \n",
    "**학습 태스크 파라미터**\n",
    "- objective: xgboost와 동일\n",
    "- metric\n",
    "    - mae, mse, binary_logloss, multi_logloss\n",
    "    \n",
    "**IO parameter**\n",
    "\n",
    "- max_bin: 연속값을 최대 몇개의 bin으로 나눌 것인지에 대한 것??\n",
    "- categorical_feature:\n",
    "- ignore_column:\n",
    "- save_binary:\n",
    "    - 데이터셋을 바이너리 파일로 저장해서 다음에 더 빨리 읽음\n",
    "\n",
    "- **나머지 파라미터는 참고자료 확인**\n",
    "\n",
    "## fit() 파라미터\n",
    "- categorical_feature\n",
    "    - 카테고리 변수를 지정하는데 사용\n",
    "- feature_name(디폴트:auto)\n",
    "    - Feature names. If ‘auto’ and data is pandas DataFrame, data columns names are used\n",
    "- eval_set\n",
    "    - 검증데이터 전달\n",
    "    - eval_set=[(train_x, train_y), (valid_x, valid_y)]\n",
    "- eval_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ab7741",
   "metadata": {},
   "source": [
    "#### lightgbm의 feature importance 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f090b2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import plot_importance\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 12))\n",
    "plot_importance(lgbm_wrapper, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b949f45",
   "metadata": {},
   "source": [
    "## 6.2 Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f5a6fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8987d933",
   "metadata": {},
   "source": [
    "# 7. cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0558082",
   "metadata": {},
   "source": [
    "## 7.1 1개 모델의 cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d489aace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571e601f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=, shuffle=True, random_state=)\n",
    "scores = cross_val_score(모델, X, y, scoring='accuracy', cv=kfold, n_jobs=-1)\n",
    "\n",
    "print(scores.mean(), scores.std())\n",
    "\n",
    "# scoring 종류 :\n",
    "    - 회귀 : 'r2'\n",
    "    - 분류 : 'accuracy', 'precision', 'recall', 'f1', 'roc_auc', 'average_precision', 'recall_macro',\n",
    "    - 군집 : \n",
    "\n",
    "# 여기서 X, y는 원본 데이터를 훈련, 테스트로 나눈 후에 train, valid로 나누기 전 훈련_X, 훈련_y\n",
    "# 이 훈련_X, 훈련_y를 다시 train, valid로 나눠서 교차검증이 이루어짐\n",
    "\n",
    "# cross_val_score에서 폴드를 나눌 때 분류에는 StratifiedKFold, 회귀에는 단순 KFold가 적용됨\n",
    "\n",
    "# cross_validate 함수를 사용하면 훈련 시간 반환, 여러개의 평가지표 전달 가능(파이썬 라이브러리를 활용한 머신러닝 p.326)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eeed9b",
   "metadata": {},
   "source": [
    "## 7.2 여러개의 모델의 cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e692ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "n_splits = 10\n",
    "kfold = KFold(n_splits=n_splits, shuffle=True, random_state=)\n",
    "cv_means = []  # cross_val의 mean\n",
    "cv_results = []   # cross_val의 result의 리스트들\n",
    "cv_stds = []\n",
    "model_names = ['이름1', '이름2', '이름3']\n",
    "model_list = [모델1, \n",
    "              모델2, \n",
    "              모델3]\n",
    "\n",
    "for model in model_list:\n",
    "    result = cross_val_score(model, X_데이터, Y_데이터, cv=kfold, scoring='accuracy', n_jobs=-1)\n",
    "    cv_means.append(result.mean())\n",
    "    cv_stds.append(result.std())\n",
    "    scores.append(cv_results)\n",
    "\n",
    "new_models_dataframe = pd.DataFrame({'CV Mean': cv_means, 'Std': cv_stds}, index=model_names)\n",
    "\n",
    "# 여기서 X, y는 원본 데이터를 훈련, 테스트로 나눈 후에 train, valid로 나누기 전 훈련_X, 훈련_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2e3562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_means 시각화 - barplot 플롯 \n",
    "plt.subplots(figsize=(12, 8))\n",
    "sns.barplot('CV Mean', model_names, palette='Set2', data=new_models_dataframe, xerr=1.96*np.array(cv_stds)/np.sqrt(n_splits))\n",
    "plt.title('Average CV Mean 평가지수 ex)Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b23bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_results 시각화 - 박스플롯 \n",
    "plt.subplots(figsize=(20, 8))\n",
    "box = pd.DataFrame(cv_results, index=model_names)\n",
    "box.T.boxplot()\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5fcecb",
   "metadata": {},
   "source": [
    "# 8. Confusion Matrix\n",
    "- binary classification 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50003cc0",
   "metadata": {},
   "source": [
    "## 8.1 단일 valid_data로 Confusion Matrix 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cdb392",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00c37468",
   "metadata": {},
   "source": [
    "## 8.2 cross validation으로 Confusion Matrix 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b2befb",
   "metadata": {},
   "source": [
    "#### heatmap 으로 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8591f192",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "f, ax = plt.subplots( , , figsize=( , ))\n",
    "\n",
    "y_pred = cross_val_predict(모델, X, Y, cv=kfold) # 각 폴드가 테스트 세트일 때 예측된 값을 반환\n",
    "sns.heatmap(confusion_matrix(Y, y_pred), annot=True, fmt='2.0f', ax=ax[ , ])\n",
    "ax[0, 0].set_title('Matrix for 모델')\n",
    "\n",
    "# 여기서 X, y는 원본 데이터를 훈련, 테스트로 나눈 후에 train, valid로 나누기 전 훈련_X, 훈련_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dae94ad",
   "metadata": {},
   "source": [
    "- cross_val_predict를 쓰지 않고 그냥 valid_X, valid_Y만 하면 1개의 폴드만을 이용해서 평가한다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e7ac2f",
   "metadata": {},
   "source": [
    "- 정확도(accuracy) : 전체 정확도    \n",
    "    - (TP + TN) / (TP + TN + FP + FN)\n",
    "- 정밀도(precision) : 양성이라고 예측한 암환자가 모두 암환자가 확실한가     \n",
    "    - TP / (TP + FP) \n",
    "- 재현율(recall, TPR) : 암환자를 놓치지 않고 모두 찾아낼 수 있는가     \n",
    "    - TP / (TP + FN)\n",
    "- 위양성률(fall-out, FPR) : 무고한 사람을 유죄로 몰지 않는가    \n",
    "    - FP / (FP + TN)\n",
    "- f1_score: 2 * precision * recall / (precision + recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aff44d3",
   "metadata": {},
   "source": [
    "## 8.3 정밀도-재현율 곡선(precision-recall curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf89ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_검증데이터, 모델.decision_function(X_검증데이터))\n",
    "\n",
    "# 판별함수값이 0에 가까운 임계값을 찾음\n",
    "close_zero = np.argmin(np.abs(thresholds))\n",
    "plt.plot(precision[close_zero], recall[close_zero], 'o', markersize=10, label='임계값 0', fillstyle='none', c='k', mew=2)\n",
    "\n",
    "plt.plot(precision, recall, label='정밀도-재현율 곡선')\n",
    "plt.xlabel('precision')\n",
    "plt.ylabel('재현율')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb05df66",
   "metadata": {},
   "source": [
    "- decision_function(X_검증)의 결과에 0이 포함되지 않을 수 있기 때문에 절댓값이 가장 작은 위치의 인덱스를 구하기 위해 argmin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4659ad02",
   "metadata": {},
   "source": [
    "#### 평균정밀도(average precision) - 정밀도-재현율 곡선의 아랫부분 면적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ee8e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "average_precision = average_precision_score(y_검증, 모델.decision_function(X_검증))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1d4ed2",
   "metadata": {},
   "source": [
    "## 8.4 ROC-AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e76fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y, 모델.predict_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e139441c",
   "metadata": {},
   "source": [
    "# 9. Hyper-Parameters Tuning\n",
    "- Manual tuning 하면서 intuition을 얻는다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76294099",
   "metadata": {},
   "source": [
    "## 9.1 GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd9075f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 모델()\n",
    "\n",
    "모델_param_grid = {'':, []}\n",
    "\n",
    "gs모델 = GridSearchCV(model, param_grid=모델_param_grid, cv=kfold, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "\n",
    "gs모델.fit(X_훈련, Y_훈련)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73071324",
   "metadata": {},
   "source": [
    "## 9.2. Randomized search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d89c5ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a018f05f",
   "metadata": {},
   "source": [
    "## 9.3 Baysian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33be5ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bff38bb",
   "metadata": {},
   "source": [
    "# 10. learning_curve 시각화\n",
    "- 훈련데이터 크기가 미치는 영향\n",
    "- train, valid 곡선이 가까우면 일반화가 잘 된다고 볼 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2152da1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, ylim=[0.5, 1.0], cv=None, n_jobs=-1, train_sizes=np.linspace(최소, 1.0, 몇등분)):\n",
    "    \"\"\"Generate a simple plot of the test and training learning curve\"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel('Training examples')\n",
    "    plt.ylabel('Score')\n",
    "    \n",
    "    train_sizes, train_scores, valid_scores = learning_curve(모델.best_estimator_, X, y, cv=kfold, n_jobs=-1, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    valid_scores_mean = np.mean(valid_scores, axis=1)\n",
    "    valid_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color='r', \n",
    "             label='Training score')\n",
    "    plt.plot(train_sizes, valid_scores_mean, 'o-', color='g', \n",
    "             label='Cross-validation score')\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, \n",
    "                     train_scores_mean + train_scores_std, alpha=0.1, color='r')\n",
    "    plt.fill_between(train_sizes, valid_scores_mean - valid_scores_std, \n",
    "                     valid_scores_mean + valid_scores_std, alpha=0.1, color='g')\n",
    "    \n",
    "    plt.legend(loc='best')\n",
    "    return plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a367b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(모델.best_estimator_, '모델 learning curves', X_훈련, Y_훈련, cv=kfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b700fc",
   "metadata": {},
   "source": [
    "# 11. Feature Importance\n",
    "- 주로 random forest로 측정\n",
    "- 모델들을 합쳐서 평균낼 수도 있다\n",
    "- Decision 기반 모델에서 계산은 feature당 누적 정보획득량으로 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e464bb3",
   "metadata": {},
   "source": [
    "## 11.1 Binary classifiacation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a15b066",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "\n",
    "feature_importance = model.feature_importances_\n",
    "Series_feat_imp = Series(feature_importance, index=데이터.columns)\n",
    "Series_feat_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b7a8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "Series_feat_imp.sort_values(ascending=True).plot.barh()\n",
    "plt.xlabel('Feature importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405ca25d",
   "metadata": {},
   "source": [
    "#### 여러개의 Feature Importance 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f029d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = \n",
    "ncols = \n",
    "fig, ax = plt.subplots(nrows, ncols, sharex='all', figsize=(15, 15))\n",
    "\n",
    "names_classifiers = [('모델1이름', 모델1.best_estimator_), \n",
    "                     ('모델2이름', 모델2.best_estimator_), \n",
    "                     ('모델3이름', 모델3.best_estimator_), \n",
    "                     ('모델4이름', 모델4.best_estimator_)]\n",
    "\n",
    "nclassifier = 0\n",
    "for row in range(nrows):\n",
    "    for col in range(ncols):\n",
    "        name = names_classifiers[nclassifier][0]\n",
    "        classifier = names_classifiers[nclassifier][1]\n",
    "        indices = np.argsort(classifier.feature_importances_)[::-1][:40]\n",
    "        g = sns.barplot(y=X_train.columns[indices][:40], x=classifier.feature_importances_[indices][:40], orient='h', ax=ax[row, col])\n",
    "        g.set_xlabel('Relative importance', fontsize=12)\n",
    "        g.set_ylabel('Features', fontsize=12)\n",
    "        g.tick_params(labelsize=9)\n",
    "        g.set_title(name + 'feature importance')\n",
    "        nclassifier += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38e4322",
   "metadata": {},
   "source": [
    "# 12. 모델간의 test데이터 예측결과 상관계수\n",
    "    - 각 모델들의 best_estimator_를 기준"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56b422b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict_모델1 = pd.Series(모델1.best_estimator_.predict(test), name='이름1')\n",
    "test_predict_모델2 = pd.Series(모델2.best_estimator_.predict(test), name='이름2')\n",
    "test_predict_모델3 = pd.Series(모델3.best_estimator_.predict(test), name='이름3')\n",
    "\n",
    "ensemble_results = pd.concat([test_predict_모델1, test_predict_모델2, test_predict_모델3], axis=1)\n",
    "\n",
    "sns.heatmap(ensemble_results.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a0a882",
   "metadata": {},
   "source": [
    "# 13. Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662ff1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking_base_datasets(model, X_train, y_train, X_test, n_folds):\n",
    "    # KFold 생성\n",
    "    kf = KFold(n_splits=n_folds, shuffle=False)\n",
    "    \n",
    "    # 메타 모델 학습 데이터 넘파이 배열 초기화\n",
    "    train_fold_pred = np.zeros((X_train.shape[0], 1))\n",
    "    test_pred = np.zeros((X_test.shape[0], n_folds))\n",
    "    print(model.__class__.__name__, 'model 시작')\n",
    "    \n",
    "    for folder_counter, (train_index, valid_index) in enumerate(kf.split(X_train)):\n",
    "        x_tr = X_train[train_index]\n",
    "        y_tr = y_train[train_index]\n",
    "        x_val = x_train[valid_index]\n",
    "        \n",
    "        model.fit(x_tr, y_tr)\n",
    "        train_fold_pred[valid_index, :] = model.predict(x_val).reshape(-1, 1)\n",
    "        test_pred[:, folder_counter] = model.predict(X_test)\n",
    "        \n",
    "    # 폴드 세트 내에서 원본 테스트 데이터를 예측한 데이터를 평균하여 테스트 데이터 생성\n",
    "    test_pred_mean = np.mean(test_pred, axis=1).reshape(-1, 1)\n",
    "    \n",
    "    return train_fold_pred, test_pred_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7cae96",
   "metadata": {},
   "outputs": [],
   "source": [
    "모델1_train, 모델1_test = get_stacking_base_datasets(모델1, X_train, y_train, X_test, 폴드수)\n",
    "모델2_train, 모델2_test = get_stacking_base_datasets(모델2, X_train, y_train, X_test, 폴드수)\n",
    "모델3_train, 모델3_test = get_stacking_base_datasets(모델3, X_train, y_train, X_test, 폴드수)\n",
    "모델4_train, 모델4_test = get_stacking_base_datasets(모델4, X_train, y_train, X_test, 폴드수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96951c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stack_final_X_train = np.concatenate((모델1_train, 모델2_train, 모델3_train, 모델4_train), axis=1)\n",
    "Stack_final_X_test = np.concatenate((모델1_test, 모델2_test, 모델3_test, 모델4_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32579bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "메타모델.fit(Stack_final_X_train, y_train)\n",
    "stack_final = 메타모델.predict(Stack_final_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61db0eae",
   "metadata": {},
   "source": [
    "#### 스태킹을 클래스로 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03ed8195",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensemble(object):\n",
    "    def __init__(self, n_splits, stacker, base_models):\n",
    "        self.n_splits = n_splits\n",
    "        self.stacker = stacker\n",
    "        self.base_models = base_models\n",
    "\n",
    "    def fit_predict(self, X, y, T):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        T = np.array(T)\n",
    "\n",
    "        folds = list(StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=314).split(X, y))\n",
    "\n",
    "        S_train = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        S_test = np.zeros((T.shape[0], len(self.base_models)))\n",
    "        for i, clf in enumerate(self.base_models):\n",
    "\n",
    "            S_test_i = np.zeros((T.shape[0], self.n_splits))\n",
    "\n",
    "            for j, (train_idx, test_idx) in enumerate(folds):\n",
    "                X_train = X[train_idx]\n",
    "                y_train = y[train_idx]\n",
    "                X_holdout = X[test_idx]\n",
    "\n",
    "\n",
    "                print (\"Base model %d: fit %s model | fold %d\" % (i+1, str(clf).split('(')[0], j+1))\n",
    "                clf.fit(X_train, y_train)\n",
    "                cross_score = cross_val_score(clf, X_train, y_train, cv=3, scoring='roc_auc')\n",
    "                print(\"cross_score [roc-auc]: %.5f [gini]: %.5f\" % (cross_score.mean(), 2*cross_score.mean()-1))\n",
    "                y_pred = clf.predict_proba(X_holdout)[:,1]                \n",
    "\n",
    "                S_train[test_idx, i] = y_pred\n",
    "                S_test_i[:, j] = clf.predict_proba(T)[:,1]\n",
    "            S_test[:, i] = S_test_i.mean(axis=1)\n",
    "\n",
    "        results = cross_val_score(self.stacker, S_train, y, cv=3, scoring='roc_auc')\n",
    "        # Calculate gini factor as 2 * AUC - 1\n",
    "        print(\"Stacker score [gini]: %.5f\" % (2 * results.mean() - 1))\n",
    "\n",
    "        self.stacker.fit(S_train, y)\n",
    "        res = self.stacker.predict_proba(S_test)[:,1]\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7e5648",
   "metadata": {},
   "outputs": [],
   "source": [
    "모델1_params = {}\n",
    "모델1_params['파라미터'] = \n",
    "모델1_params['파라미터'] = \n",
    "모델1_params['파라미터'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b81f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base models\n",
    "모델1 = 모델(**모델1_params**)\n",
    "\n",
    "모델2 = 모델(**모델2_params**)\n",
    "\n",
    "# stacking model\n",
    "meta_model =  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71ff446",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = Ensemble(n_splits=, stacker=meta_model, base_models = (모델1, 모델2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4c6691",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = stack.fit_predict(훈련데이터, 훈련타겟, 테스트데이터)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff02077e",
   "metadata": {},
   "source": [
    "# 14. 기타 캐글 앙상블 테크닉\n",
    "- porto competition 2등: 스태킹의 바깥 iteration에서 lightGBM의 여러개의 'seed'를 for문 돌려서 또 앙상블"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geoenv",
   "language": "python",
   "name": "geoenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
